---
title: "Emotional Attributes of diverging political spheres on Twitter"
author: "Florian Klement, David Siegl, Shirin Yanni"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


```{r}
library(rtweet)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(quanteda)
library(purrr)
library(data.table)
library(tm)
quanteda::stopwords
```

<b>Accessing the Twitter-API</b>
```{r}
consumerKey = "X"
consumerSecret = "X"
accessToken = "X-X"
accessSecret = "X"
options(httr_oauth_cache=TRUE)
twitter_token <- create_token(
  consumer_key = consumerKey,
  consumer_secret = consumerSecret,
  access_token = accessToken,
  access_secret = accessSecret)
```


<b>Loading some data</b>
```{r}
sheet <- read.csv("./Emotion Analysis - Twitter.csv")
id_list <- as.list(sheet$Twitter.ID)
```


<b>Defining Function for Twitter-Scraping</b>
```{r}
scrape_tweets <- function(userID, n_tweets, filename){
  tweets <- get_timeline(userID, n_tweets, include_rts=FALSE, exclude_replies=TRUE)
  tweets_df <- as_data_frame(tweets)
  tweets_df <- tweets_df %>%
    select(c(status_id, text, screen_name, created_at, favorite_count, retweet_count))
  write.csv(tweets_df, paste(filename,"-tweets.csv", sep = ""), row.names = FALSE)
}

# for (id in id_list) {
#   scrape_tweets(id, 3200, id)
# }
```


<b>Loading the Tweets</b>
```{r}
tweets_files <- list.files("./data/raw")

for (i in 1:length(tweets_files)) {                              
  assign(paste0("tweets_", i),                                   
         read.csv(paste0("./data/raw/",
                   tweets_files[i])))
}
```


<b>Preprocessing</b>
```{r}
tweets_1 <- top_n(tweets_1, 300, created_at)
tweets_2 <- top_n(tweets_2, 300, created_at)
tweets_4 <- top_n(tweets_4, 300, created_at)
tweets_5 <- top_n(tweets_5, 300, created_at)
tweets_6 <- top_n(tweets_6, 300, created_at)
tweets_7 <- top_n(tweets_7, 300, created_at)
tweets_8 <- top_n(tweets_8, 300, created_at)
tweets_9 <- top_n(tweets_9, 300, created_at)
tweets_10 <- top_n(tweets_10, 300, created_at)
tweets_11 <- top_n(tweets_11, 300, created_at)
tweets_12 <- top_n(tweets_12, 300, created_at)
tweets_13 <- top_n(tweets_13, 300, created_at)
tweets_14 <- top_n(tweets_14, 300, created_at)
tweets_15 <- top_n(tweets_15, 300, created_at)
tweets_16 <- top_n(tweets_16, 300, created_at)
```


```{r}
cleaning_tweets <- function(text){
  text <- gsub("http.+", "", text)
  text <- gsub(",", "", text)
  text <- gsub("[[:punct:-[#]]", "", text)
  text <- gsub("[[:digit:]]", "", text)
  text <- gsub("  ", " ", text)
}

tweets_1 <- tweets_1 %>%
  rowwise() %>%
  mutate(text = cleaning_tweets(text))

write.csv(tweets_1, "./data/clean/@ABaerbock-tweets_clean.csv", row.names = F)
```


<b>Processing_II</b>
```{r}
collection <-
    list.files(path = "./data/raw/",
               full.names = T) %>% 
    map_df(~read_csv(., col_types = cols(.default = "c")))
collection
```

Sample unausgewogen
```{r}
table(collection$screen_name)
```
```{r}
collection <- collection %>%
  select('status_id', 'text', 'screen_name', 'created_at', 'favorite_count', 'retweet_count')
str(collection)
collection <- drop_na(collection)
```

```{r}
names <- as.list(unique(collection$screen_name))
set.seed(1)

df_total <- data.frame()

for (i in names) {
 dat <-  collection %>%
  filter(screen_name == i) %>%
   sample_n(298, replace = FALSE) 
   

 df_total <- rbind(df_total,dat, use.names=TRUE)
}

#coll_s = do.call(rbind, datalist)
```

```{r}
coll_s <- df_total %>%
filter(screen_name != TRUE)
unique(coll_s$screen_name)
```
```{r}
coll_s <- coll_s %>%
  #rowwise() %>%
  mutate(text = cleaning_tweets(text))

coll_s
```
```{r}
head(tweets_1)
```
