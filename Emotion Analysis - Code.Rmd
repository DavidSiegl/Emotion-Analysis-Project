---
title: "Emotional Attributes of diverging political spheres on Twitter"
author: "Florian Klement, David Siegl, Shirin Yanni"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


```{r}
library(rtweet)
library(ggplot2)
library(tidyverse)
library(gsubfn)
library(quanteda)
library(tm)
quanteda::stopwords
```

<b>Accessing the Twitter-API</b>
```{r}
consumerKey = "X"
consumerSecret = "X"
accessToken = "X-X"
accessSecret = "X"
options(httr_oauth_cache=TRUE)
twitter_token <- create_token(
  consumer_key = consumerKey,
  consumer_secret = consumerSecret,
  access_token = accessToken,
  access_secret = accessSecret)
```


<b>Loading some data</b>
```{r}
sheet <- read.csv("./Emotion Analysis - Twitter.csv")
id_list <- as.list(sheet$Twitter.ID)
```


<b>Defining Function for Twitter-Scraping</b>
```{r}
scrape_tweets <- function(userID, n_tweets, filename){
  tweets <- get_timeline(userID, n_tweets, include_rts=FALSE, exclude_replies=TRUE)
  tweets_df <- as_data_frame(tweets)
  tweets_df <- tweets_df %>%
    select(c(status_id, text, screen_name, created_at, favorite_count, retweet_count))
  write.csv(tweets_df, paste(filename,"-tweets.csv", sep = ""), row.names = FALSE)
}

# for (id in id_list) {
#   scrape_tweets(id, 3200, id)
# }
```


<b>Loading the Tweets</b>
```{r}
tweets_files <- list.files("./data/raw")

for (i in 1:length(tweets_files)) {                              
  assign(paste0("tweets_", i),                                   
         read.csv(paste0("./data/raw/",
                   tweets_files[i])))
}
```


<b>Preprocessing</b>
```{r}
tweets_1 <- top_n(tweets_1, 300, created_at) #sampling the tweets for n=300
tweets_2 <- top_n(tweets_2, 300, created_at)
tweets_4 <- top_n(tweets_4, 300, created_at)
tweets_5 <- top_n(tweets_5, 300, created_at)
tweets_6 <- top_n(tweets_6, 300, created_at)
tweets_7 <- top_n(tweets_7, 300, created_at)
tweets_8 <- top_n(tweets_8, 300, created_at)
tweets_9 <- top_n(tweets_9, 300, created_at)
tweets_10 <- top_n(tweets_10, 300, created_at)
tweets_11 <- top_n(tweets_11, 300, created_at)
tweets_12 <- top_n(tweets_12, 300, created_at)
tweets_13 <- top_n(tweets_13, 300, created_at)
tweets_14 <- top_n(tweets_14, 300, created_at)
tweets_15 <- top_n(tweets_15, 300, created_at)
tweets_16 <- top_n(tweets_16, 300, created_at)
```


```{r}
cleaning_tweets <- function(text){
  text <- gsub("http.+", "", text)
  text <- gsub(",", "", text)
  text <- gsubfn(pattern = "[[:punct:]]", engine = "R",
       replacement = function(x) ifelse(x == "#", "#", ""), 
       text)
  text <- gsub("[[:digit:]]", "", text)
  text <- gsub("  ", " ", text)
  text <- tolower(text)
}
```


```{r}
df_full <- rbind(tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, by = (c("status_id", "text", "screen_name", "created_at", "favorite_count", "retweet_count")), all = TRUE)

unique(df_full$screen_name)

df_full <- df_full %>%
  filter(screen_name != TRUE) %>%
  filter(screen_name != "screen_name")
 
unique(df_full$screen_name)

df_full <- df_full %>%
  rowwise() %>%
  mutate(text = cleaning_tweets(text)) %>%
  mutate(date = as.Date(created_at))

write.csv(df_full, "./data/clean/tweets_clean.csv", row.names = FALSE)
```


```{r}
tweets_clean <- read.csv("./data/clean/tweets_clean.csv")

join_info <- sheet %>%
  mutate(screen_name = gsub("@", "", Twitter.ID))

tweets_clean_joined <- left_join(tweets_clean, join_info, by = "screen_name")
tweets_clean_joined <- tweets_clean_joined %>%
  select(-c(Link, Follower, Notes, Twitter.ID))
tweets_clean_joined <- rename(tweets_clean_joined, name = Name, party = Party, country = Country, left_right = left.right)

write.csv(tweets_clean_joined, "./data/clean/tweets_clean_joined.csv", row.names = FALSE)
```


<b>Joining the emotion dictionary</b>
```{r}
tweets_clean_joined <- read.csv("./data/clean/tweets_clean_joined.csv")

stopwords_de <- stopwords("german")
stopwords_add <- c("dass", "„", "–")
stopwords_de <- append(stopwords_de, stopwords_add)

dict <- read_tsv("./dict/de.tsv")
dict$word <- tolower(dict$word)
```


```{r}
tweets_words <- function(text){
  words <- strsplit(text, " ")[[1]]
  tf <- table(words)           
  tf <- as.data.frame(tf)
  colnames(tf) <- c("word", "frequency")
  tf <- subset(tf, is.element(word, stopwords_de) == FALSE)
  return(tf)
}

join_dict_valence <- function(words, dict){
  tf <- words
  combined <- merge(tf, dict, by="word")
  score_valence <- sum(combined$frequency * combined$valence) / sum(combined$frequency)
  return(score_valence)
}

join_dict_arousal <- function(words, dict){
  tf <- words
  combined <- merge(tf, dict, by="word")
  score_arousal <- sum(combined$frequency * combined$arousal) / sum(combined$frequency)
  return(score_arousal)
}

join_dict_dominance <- function(words, dict){
  tf <- words
  combined <- merge(tf, dict, by="word")
  score_dominance <- sum(combined$frequency * combined$dominance) / sum(combined$frequency)
  return(score_dominance)
}
```


<b>Getting valence, arousal and dominance score for all users</b>
```{r}
id_list <- gsub("@", "", id_list)

for(i in id_list){
 assign(paste0("tweets_user_", i),
        tweets_clean_joined %>%
  filter(screen_name == i))
}

list_var <- ls(pattern = "tweets_user_*")
```


```{r}
texts <- paste(tweets_clean_joined$text, tweets_clean_joined$text, sep = " ")
df <- data.frame(words = character(0), frequency = numeric(0))
valence_scores <- c()
arousal_scores <- c()
dominance_scores <- c()

for(i in 1:nrow(tweets_clean_joined)){
    text <- texts[i]
    words <- tweets_words(text)
    df <- rbind(df, words)
    scores <- join_dict_valence(df, dict)
    valence_scores <- c(valence_scores, scores)
}
```


```{r}
for(i in 1:nrow(tweets_clean_joined)){
    text <- texts[i]
    words <- tweets_words(text)
    df <- rbind(df, words)
    scores <- join_dict_arousal(df, dict)
    arousal_scores <- c(arousal_scores, scores)
}
```


```{r}
for(i in 1:nrow(tweets_clean_joined)){
    text <- texts[i]
    words <- tweets_words(text)
    df <- rbind(df, words)
    scores <- join_dict_dominance(df, dict)
    dominance_scores <- c(dominance_scores, scores)
}
```


```{r}
test <- cbind(tweets_user_ABaerbock, valence_scores)
```


<b>Quanteda Analysis</b>
```{r}
corp_tweet <- corpus(tweets_clean_joined, text_field = "text")
print(corp_tweet)
summary(corp_tweet, 5)
tok_tweet <- tokens(corp_tweet)
tok_clean <- tokens_remove(tok_tweet, pattern = stopwords("german"))
tok_clean <- tokens_select(tok_clean, pattern = o, selection = "remove")
View(tok_clean)
tweet_matrix <- dfm(tok_clean)
tweet_matrix
```