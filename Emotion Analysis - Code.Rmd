---
title: "Emotional Attributes of diverging political spheres on Twitter"
author: "Florian Klement, David Siegl, Shirin Yanni"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


```{r}
library(rtweet)
library(ggplot2)
library(tidyverse)
library(gsubfn)
library(quanteda)
library(tm)
quanteda::stopwords
```

<b>Accessing the Twitter-API</b>
```{r}
consumerKey = "X"
consumerSecret = "X"
accessToken = "X-X"
accessSecret = "X"
options(httr_oauth_cache=TRUE)
twitter_token <- create_token(
  consumer_key = consumerKey,
  consumer_secret = consumerSecret,
  access_token = accessToken,
  access_secret = accessSecret)
```


<b>Loading some data</b>
```{r}
sheet <- read.csv("./Emotion Analysis - Twitter.csv")
id_list <- as.list(sheet$Twitter.ID)
```


<b>Defining Function for Twitter-Scraping</b>
```{r}
scrape_tweets <- function(userID, n_tweets, filename){
  tweets <- get_timeline(userID, n_tweets, include_rts=FALSE, exclude_replies=TRUE)
  tweets_df <- as_data_frame(tweets)
  tweets_df <- tweets_df %>%
    select(c(status_id, text, screen_name, created_at, favorite_count, retweet_count))
  write.csv(tweets_df, paste(filename,"-tweets.csv", sep = ""), row.names = FALSE)
}

# for (id in id_list) {
#   scrape_tweets(id, 3200, id)
# }
```


<b>Loading the Tweets</b>
```{r}
tweets_files <- list.files("./data/raw")

for (i in 1:length(tweets_files)) {                              
  assign(paste0("tweets_", i),                                   
         read.csv(paste0("./data/raw/",
                   tweets_files[i])))
}
```


<b>Preprocessing</b>
```{r}
tweets_1 <- top_n(tweets_1, 300, created_at) #sampling the tweets for n=300
tweets_2 <- top_n(tweets_2, 300, created_at)
tweets_4 <- top_n(tweets_4, 300, created_at)
tweets_5 <- top_n(tweets_5, 300, created_at)
tweets_6 <- top_n(tweets_6, 300, created_at)
tweets_7 <- top_n(tweets_7, 300, created_at)
tweets_8 <- top_n(tweets_8, 300, created_at)
tweets_9 <- top_n(tweets_9, 300, created_at)
tweets_10 <- top_n(tweets_10, 300, created_at)
tweets_11 <- top_n(tweets_11, 300, created_at)
tweets_12 <- top_n(tweets_12, 300, created_at)
tweets_13 <- top_n(tweets_13, 300, created_at)
tweets_14 <- top_n(tweets_14, 300, created_at)
tweets_15 <- top_n(tweets_15, 300, created_at)
tweets_16 <- top_n(tweets_16, 300, created_at)
```


```{r}
cleaning_tweets <- function(text){
  text <- gsub("http.+", "", text)
  text <- gsub(",", "", text)
  text <- gsubfn(pattern = "[[:punct:]]", engine = "R",
       replacement = function(x) ifelse(x == "#", "#", ""), 
       text)
  text <- gsub("[[:digit:]]", "", text)
  text <- gsub("  ", " ", text)
  text <- tolower(text)
}
```


```{r}
list <- list(tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16)
df_full <- rbind(tweets_1, tweets_2, tweets_3, tweets_4, tweets_5, tweets_6, tweets_7, tweets_8, tweets_9, tweets_10, tweets_11, tweets_12, tweets_13, tweets_14, tweets_15, tweets_16, by = (c("status_id", "text", "screen_name", "created_at", "favorite_count", "retweet_count")), all = TRUE)

unique(df_full$screen_name)

df_full <- df_full %>%
  filter(screen_name != TRUE) %>%
  filter(screen_name != "screen_name")
 
unique(df_full$screen_name)

df_full <- df_full %>%
  rowwise() %>%
  mutate(text = cleaning_tweets(text))

write.csv(df_full, "./data/clean/tweets_clean.csv", row.names = FALSE)
```


```{r}
nlp_tweets <- function(text){
  words = strsplit(text, " ")[[1]]  
}
```



